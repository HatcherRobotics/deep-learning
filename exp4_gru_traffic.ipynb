{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义dataset\n",
    "class my_Dataset(data.Dataset):#继承？\n",
    "    def __init__(self, features, labels):\n",
    "        self.X = features\n",
    "        self.y = labels\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrafficDataset:\n",
    "    def __init__(self, sensor_num=10, target=0):\n",
    "        # 选取适当的检测器用作序列数据\n",
    "        self.raw_data = np.load('./traffic-flow/traffic.npz')['data']\n",
    "        self.sensor_num = sensor_num\n",
    "        self.target = target\n",
    "        # 数据标准化\n",
    "        self.min = self.raw_data.min()\n",
    "        self.max = self.raw_data.max()\n",
    "        self.data = (self.raw_data - self.min) / (self.max - self.min)\n",
    "\n",
    "    def denormalize(self, x):\n",
    "        return x * (self.max - self.min) + self.min\n",
    "\n",
    "    def construct_set(self, train_por=0.6,val_por=0.2,test_por=0.2, window_size=12,label=0):\n",
    "        train_x = []\n",
    "        train_y = []\n",
    "        val_x = []\n",
    "        val_y = []\n",
    "        test_x = []\n",
    "        test_y = []\n",
    "        len_train = int(self.data.shape[0] * train_por)\n",
    "        len_val = int(self.data.shape[0] * val_por)\n",
    "        len_test = int(self.data.shape[0] * test_por)\n",
    "        train_seqs = self.data[:len_train]\n",
    "        val_seqs = self.data[len_train:len_val+len_train]\n",
    "        test_seqs = self.data[len_train+len_val:len_val+len_train+len_test]\n",
    "\n",
    "        for i in range(train_seqs.shape[0] - window_size):\n",
    "            train_x.append(train_seqs[i:i+window_size, self.sensor_num, :].squeeze())\n",
    "            train_y.append(train_seqs[i+window_size, self.sensor_num, self.target].squeeze())\n",
    "\n",
    "        for i in range(val_seqs.shape[0] - window_size):\n",
    "            val_x.append(val_seqs[i:i+window_size, self.sensor_num, :].squeeze())\n",
    "            val_y.append(val_seqs[i+window_size, self.sensor_num, self.target].squeeze())\n",
    "\n",
    "        for i in range(test_seqs.shape[0] - window_size):\n",
    "            test_x.append(test_seqs[i:i+window_size, self.sensor_num, :].squeeze())\n",
    "            test_y.append(test_seqs[i+window_size, self.sensor_num, self.target].squeeze())\n",
    "        \n",
    "        train_set = my_Dataset(torch.Tensor(train_x), torch.Tensor(train_y))\n",
    "        val_set = my_Dataset(torch.Tensor(val_x), torch.Tensor(val_y))\n",
    "        test_set = my_Dataset(torch.Tensor(test_x), torch.Tensor(test_y))\n",
    "        return train_set, val_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrafficData = TrafficDataset()\n",
    "train_set, val_set, test_set = TrafficData.construct_set()\n",
    "batch_size = 64\n",
    "train_loader = data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=4, drop_last=True)\n",
    "val_loader = data.DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=4, drop_last=True)\n",
    "test_loader = data.DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=4, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "input_size = train_set.X.shape[-1]\n",
    "hidden_size = 64\n",
    "output_size = 1\n",
    "seq_len = 12\n",
    "lr = 0.0001\n",
    "epochs = 80\n",
    "loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru = nn.GRU(input_size=input_size,hidden_size=hidden_size,output_size=output_size,num_layers=1).to(device)\n",
    "optimizer = torch.optim.Adam(gru.parameters,lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_lst, val_loss_lst, \\\n",
    "    train_score_lst, val_score_lst, stop_epoch = train(gru, train_loader, val_loader, test_loader,\n",
    "                                                        loss_func, TrafficData.denormalize, optimizer, epochs,\n",
    "                                                        early_stop=20, device=device, output_model=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(stop_epoch, train_loss_lst, val_loss_lst, y_label='Loss')\n",
    "plot_metric(train_score_lst)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c68792f7cd82460065c5d613846083f799a914df57fed46700f5555136f46f97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
